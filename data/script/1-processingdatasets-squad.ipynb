{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading dataset","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, load_dataset, concatenate_datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:00.180483Z","iopub.execute_input":"2025-04-15T17:00:00.180842Z","iopub.status.idle":"2025-04-15T17:00:02.661606Z","shell.execute_reply.started":"2025-04-15T17:00:00.180811Z","shell.execute_reply":"2025-04-15T17:00:02.660750Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"dataset = load_dataset(\"rajpurkar/squad_v2\")\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:04.543396Z","iopub.execute_input":"2025-04-15T17:00:04.543735Z","iopub.status.idle":"2025-04-15T17:00:06.566129Z","shell.execute_reply.started":"2025-04-15T17:00:04.543707Z","shell.execute_reply":"2025-04-15T17:00:06.565271Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d054bad0f044c4186c7c4c15519164d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"593174609ed747feaffe4cf49d7064bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fccdf2d9040c489fa30f2d67d944b186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a7c7404f47143829ab9998f577ccbda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd11705844604658aceab5ac5b96c1f5"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 130319\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 11873\n    })\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:09.272949Z","iopub.execute_input":"2025-04-15T17:00:09.273448Z","iopub.status.idle":"2025-04-15T17:00:09.280001Z","shell.execute_reply.started":"2025-04-15T17:00:09.273418Z","shell.execute_reply":"2025-04-15T17:00:09.278643Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'id': '56be85543aeaaa14008c9063',\n 'title': 'Beyoncé',\n 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n 'question': 'When did Beyonce start becoming popular?',\n 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dataset['validation'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:11.456320Z","iopub.execute_input":"2025-04-15T17:00:11.456648Z","iopub.status.idle":"2025-04-15T17:00:11.462227Z","shell.execute_reply.started":"2025-04-15T17:00:11.456618Z","shell.execute_reply":"2025-04-15T17:00:11.461488Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'id': '56ddde6b9a695914005b9628',\n 'title': 'Normans',\n 'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n 'question': 'In what country is Normandy located?',\n 'answers': {'text': ['France', 'France', 'France', 'France'],\n  'answer_start': [159, 159, 159, 159]}}"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"len(dataset[\"train\"].filter(lambda row: row[\"question\"] is None))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:13.695168Z","iopub.execute_input":"2025-04-15T17:00:13.695451Z","iopub.status.idle":"2025-04-15T17:00:15.595405Z","shell.execute_reply.started":"2025-04-15T17:00:13.695428Z","shell.execute_reply":"2025-04-15T17:00:15.594472Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c0cf4d93e44557912e2841541e6b5c"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"len(dataset[\"validation\"].filter(lambda row: row[\"question\"] is None))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:16.374787Z","iopub.execute_input":"2025-04-15T17:00:16.375104Z","iopub.status.idle":"2025-04-15T17:00:16.573762Z","shell.execute_reply.started":"2025-04-15T17:00:16.375077Z","shell.execute_reply":"2025-04-15T17:00:16.573030Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b99a51473a4f3db35f1a896c92d1f0"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Exploring Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:18.308301Z","iopub.execute_input":"2025-04-15T17:00:18.308625Z","iopub.status.idle":"2025-04-15T17:00:18.312091Z","shell.execute_reply.started":"2025-04-15T17:00:18.308592Z","shell.execute_reply":"2025-04-15T17:00:18.311321Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# top 10 unique titles in train\n\ntrain_df = pd.DataFrame(dataset['train'])\n\nvalue_counts = train_df['title'].value_counts()\nprint(f\"Total count of unique titles: {len(value_counts)}\\nTop 10: {value_counts.head(10)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:19.392293Z","iopub.execute_input":"2025-04-15T17:00:19.392625Z","iopub.status.idle":"2025-04-15T17:00:27.602422Z","shell.execute_reply.started":"2025-04-15T17:00:19.392591Z","shell.execute_reply":"2025-04-15T17:00:27.601656Z"}},"outputs":[{"name":"stdout","text":"Total count of unique titles: 442\nTop 10: title\nQueen_Victoria             883\nNew_York_City              817\nAmerican_Idol              790\nBeyoncé                    753\nFrédéric_Chopin            697\nBuddhism                   610\nPharmaceutical_industry    586\nNew_Haven,_Connecticut     582\nPremier_League             551\nHunting                    531\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# top 10 unique titles in validation\n\nvalid_df = pd.DataFrame(dataset['validation'])\n\nvalue_counts_2 = valid_df['title'].value_counts()\nprint(f\"Total count of unique titles: {len(value_counts_2)}\\nTop 10: {value_counts_2.head(10)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:27.603397Z","iopub.execute_input":"2025-04-15T17:00:27.603747Z","iopub.status.idle":"2025-04-15T17:00:28.328333Z","shell.execute_reply.started":"2025-04-15T17:00:27.603719Z","shell.execute_reply":"2025-04-15T17:00:28.327420Z"}},"outputs":[{"name":"stdout","text":"Total count of unique titles: 35\nTop 10: title\nEconomic_inequality                515\nRhine                              498\nWarsaw                             486\nImmune_system                      458\nYuan_dynasty                       445\nSteam_engine                       444\nHuguenot                           424\nEuropean_Union_law                 421\nComputational_complexity_theory    418\nOxygen                             415\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# any intersecting titles?\nvc_train = set(value_counts.index)\nvc_valid = set(value_counts_2.index)\n\nvc_train.intersection(vc_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:28.329681Z","iopub.execute_input":"2025-04-15T17:00:28.329917Z","iopub.status.idle":"2025-04-15T17:00:28.335222Z","shell.execute_reply.started":"2025-04-15T17:00:28.329897Z","shell.execute_reply":"2025-04-15T17:00:28.334323Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"set()"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Obtaining embeddings of all validation examples","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\nimport torch\nimport numpy as np\nimport os\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:33.448363Z","iopub.execute_input":"2025-04-15T17:00:33.448714Z","iopub.status.idle":"2025-04-15T17:00:41.371292Z","shell.execute_reply.started":"2025-04-15T17:00:33.448685Z","shell.execute_reply":"2025-04-15T17:00:41.370347Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9089ed23d9544faa9ae71c71ffd5696c"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Loading model and tokenizer","metadata":{}},{"cell_type":"code","source":"# setting env vars\nset_seed(1234)\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# setting notebook vars\nmodel_name = 'openai-community/gpt2'\n# model_name = \"google/long-t5-tglobal-xl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:41.372386Z","iopub.execute_input":"2025-04-15T17:00:41.372823Z","iopub.status.idle":"2025-04-15T17:00:52.269971Z","shell.execute_reply.started":"2025-04-15T17:00:41.372798Z","shell.execute_reply":"2025-04-15T17:00:52.269283Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name, \n                                             torch_dtype=torch.bfloat16, \n                                             output_hidden_states=True,\n                                             return_dict_in_generate = True, # neccessary for output hidden states\n                                             device_map=\"auto\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:52.271265Z","iopub.execute_input":"2025-04-15T17:00:52.271862Z","iopub.status.idle":"2025-04-15T17:00:58.148319Z","shell.execute_reply.started":"2025-04-15T17:00:52.271837Z","shell.execute_reply":"2025-04-15T17:00:58.147643Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d489ce24cb624909b8c0bbff264f108f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b964647a62245bfabb4d1098032115d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61dcd89ece5d47ecafb04f0f1a186502"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"578908857ca448bfa322e8062474e6a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"657ae355ba5544beae7800fcbad5886b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f7a34508574875b0d9cdfab06916c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15021119d772471a856e919dc8f5c0fa"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# adding pad token (to gpt models only)\nnum_added_toks = tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})\nprint(\"We have added\", num_added_toks, \"tokens\")\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.config.pad_token_id = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:00:58.149176Z","iopub.execute_input":"2025-04-15T17:00:58.149461Z","iopub.status.idle":"2025-04-15T17:00:58.744243Z","shell.execute_reply.started":"2025-04-15T17:00:58.149428Z","shell.execute_reply":"2025-04-15T17:00:58.743575Z"}},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"},{"name":"stdout","text":"We have added 1 tokens\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Generating embeddings","metadata":{}},{"cell_type":"code","source":"import math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:01:00.815497Z","iopub.execute_input":"2025-04-15T17:01:00.815834Z","iopub.status.idle":"2025-04-15T17:01:00.819400Z","shell.execute_reply.started":"2025-04-15T17:01:00.815809Z","shell.execute_reply":"2025-04-15T17:01:00.818647Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"embed_filename = \"./train_embeddings_gpt2.pt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:01:02.137309Z","iopub.execute_input":"2025-04-15T17:01:02.137661Z","iopub.status.idle":"2025-04-15T17:01:02.141207Z","shell.execute_reply.started":"2025-04-15T17:01:02.137631Z","shell.execute_reply":"2025-04-15T17:01:02.140409Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def get_embeddings(texts: list[str], tokenizer, model, batch_size: int =10, log_progress: bool =True) -> torch.tensor:\n    # determine number of buckets\n    num_buckets = math.ceil(len(texts) / batch_size)\n    if log_progress:\n        print(f\"Processing in batches of {batch_size}. Total number of batches: {num_buckets}\")\n\n    # split data into buckets and generate embeddings\n    vectors = []\n    counter = 0\n    for bucket in np.array_split(texts, num_buckets):\n        if len(bucket) == 0:  # Skip empty buckets\n            continue\n        \n        tokens = tokenizer(bucket.tolist(), padding = True, truncation=True, return_tensors=\"pt\").to('cuda')\n        with torch.no_grad():\n            embeddings = model(**tokens).hidden_states[-1].mean(dim=1).detach().cpu()\n            # embeddings = model(**tokens).encoder_last_hidden_state.mean(dim=1).detach().cpu()\n            # outputs = model.encoder(input_ids=tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])\n            # embeddings = outputs.last_hidden_state.mean(dim=1).detach().cpu()\n        \n        vectors.append(embeddings)\n        \n        if log_progress and counter % 100 == 0:\n            print(f\"Finished processing batch #{counter}\")\n        \n        counter += 1\n    \n    return torch.concatenate(vectors)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:01:05.756223Z","iopub.execute_input":"2025-04-15T17:01:05.756511Z","iopub.status.idle":"2025-04-15T17:01:05.762418Z","shell.execute_reply.started":"2025-04-15T17:01:05.756487Z","shell.execute_reply":"2025-04-15T17:01:05.761625Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"dataset['train']['question'][104006]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:01:26.429130Z","iopub.execute_input":"2025-04-15T17:01:26.429429Z","iopub.status.idle":"2025-04-15T17:01:26.557126Z","shell.execute_reply.started":"2025-04-15T17:01:26.429406Z","shell.execute_reply":"2025-04-15T17:01:26.556363Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'Are there any other areas of America Venezuelans settled in?'"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Proceed to next section unless you want to regenerate the embeddings","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\ntrain_embeddings = get_embeddings(dataset['train']['question'], tokenizer, model, 50)\nprint(f\"Embedding {len(train_embeddings)} records took {(time.time() - start_time)} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:01:54.822394Z","iopub.execute_input":"2025-04-15T17:01:54.822726Z","iopub.status.idle":"2025-04-15T17:07:07.903935Z","shell.execute_reply.started":"2025-04-15T17:01:54.822701Z","shell.execute_reply":"2025-04-15T17:07:07.903094Z"}},"outputs":[{"name":"stdout","text":"Processing in batches of 50. Total number of batches: 2607\nFinished processing batch #0\nFinished processing batch #100\nFinished processing batch #200\nFinished processing batch #300\nFinished processing batch #400\nFinished processing batch #500\nFinished processing batch #600\nFinished processing batch #700\nFinished processing batch #800\nFinished processing batch #900\nFinished processing batch #1000\nFinished processing batch #1100\nFinished processing batch #1200\nFinished processing batch #1300\nFinished processing batch #1400\nFinished processing batch #1500\nFinished processing batch #1600\nFinished processing batch #1700\nFinished processing batch #1800\nFinished processing batch #1900\nFinished processing batch #2000\nFinished processing batch #2100\nFinished processing batch #2200\nFinished processing batch #2300\nFinished processing batch #2400\nFinished processing batch #2500\nFinished processing batch #2600\nEmbedding 130319 records took 313.0769011974335 seconds\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Embedding 130319 records took 313.0769011974335 seconds","metadata":{}},{"cell_type":"code","source":"# print(f\"Length of embedding is: {len(validation_embeddings[0])}\\nSample of single embedding: {validation_embeddings[0]}\")\nprint(f\"Length of embedding is: {len(train_embeddings[0])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:07.905126Z","iopub.execute_input":"2025-04-15T17:07:07.905418Z","iopub.status.idle":"2025-04-15T17:07:07.909590Z","shell.execute_reply.started":"2025-04-15T17:07:07.905396Z","shell.execute_reply":"2025-04-15T17:07:07.908828Z"}},"outputs":[{"name":"stdout","text":"Length of embedding is: 768\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# checking if any embedding contains Nan\nprint(torch.isnan(train_embeddings).any())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:07.911213Z","iopub.execute_input":"2025-04-15T17:07:07.911483Z","iopub.status.idle":"2025-04-15T17:07:08.112105Z","shell.execute_reply.started":"2025-04-15T17:07:07.911463Z","shell.execute_reply":"2025-04-15T17:07:08.111164Z"}},"outputs":[{"name":"stdout","text":"tensor(False)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"torch.any(torch.isnan(train_embeddings), dim=1).nonzero(as_tuple=True)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:08.113139Z","iopub.execute_input":"2025-04-15T17:07:08.113450Z","iopub.status.idle":"2025-04-15T17:07:08.303732Z","shell.execute_reply.started":"2025-04-15T17:07:08.113428Z","shell.execute_reply":"2025-04-15T17:07:08.302833Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"tensor([], dtype=torch.int64)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"torch.save(train_embeddings, embed_filename)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:08.304737Z","iopub.execute_input":"2025-04-15T17:07:08.305028Z","iopub.status.idle":"2025-04-15T17:07:08.718397Z","shell.execute_reply.started":"2025-04-15T17:07:08.304993Z","shell.execute_reply":"2025-04-15T17:07:08.717338Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Obtain few shot examples for each test example","metadata":{}},{"cell_type":"code","source":"# retrieving embeddings\ntrain_embeddings = torch.load(embed_filename)\nlen(train_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:31.772367Z","iopub.execute_input":"2025-04-15T17:07:31.772682Z","iopub.status.idle":"2025-04-15T17:07:31.928159Z","shell.execute_reply.started":"2025-04-15T17:07:31.772655Z","shell.execute_reply":"2025-04-15T17:07:31.927451Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-24-7e5c048352d0>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  train_embeddings = torch.load(embed_filename)\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"130319"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nfrom tqdm import tqdm  # For progress bars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:35.535204Z","iopub.execute_input":"2025-04-15T17:07:35.535498Z","iopub.status.idle":"2025-04-15T17:07:35.539194Z","shell.execute_reply.started":"2025-04-15T17:07:35.535475Z","shell.execute_reply":"2025-04-15T17:07:35.538238Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def obtain_few_shot_examples(batch, topn=2, embed_batch_size: int=7):\n    # obtain embedding for example\n    batch_embeddings = get_embeddings(batch['question'], tokenizer, model, embed_batch_size, log_progress=False)\n    # compute pairwise cossim with all corpus examples\n    similarities = cosine_similarity(batch_embeddings.float().numpy(), train_embeddings.float().numpy())\n\n    few_shot_topn = []\n    \n    # only keep topn examples\n    for sim_i in range(len(similarities)):\n        topn_indices = np.argsort(similarities[sim_i])[-topn:][::-1]\n        few_shot_topn.append([dataset['train'][int(topn_i)] for topn_i in topn_indices])\n        \n    batch = batch.add_column('few_shot', few_shot_topn)\n\n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:38.375406Z","iopub.execute_input":"2025-04-15T17:07:38.375749Z","iopub.status.idle":"2025-04-15T17:07:38.380850Z","shell.execute_reply.started":"2025-04-15T17:07:38.375720Z","shell.execute_reply":"2025-04-15T17:07:38.379946Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def obtain_few_shot_examples_in_batches(data, batch_size: int=5, topn: int=2, log_progress: bool =True):\n    # determine number of buckets\n    num_buckets = math.ceil(len(data) / batch_size)\n    if log_progress:\n        print(f\"Processing in batches of {batch_size}. Total number of batches: {num_buckets}\")\n\n    all_buckets = []\n\n    # split data into buckets\n    counter = 0\n    for i in range(num_buckets):\n        start = i * batch_size\n        end = (i + 1) * batch_size if i < num_buckets - 1 else len(data)\n        \n        # Create a Dataset subset\n        bucket = data.select(range(start, end))\n\n        if len(bucket) == 0:  # Skip empty buckets\n            continue\n        \n        all_buckets.append(obtain_few_shot_examples(bucket, topn))\n        \n        if log_progress and counter % 50 == 0:\n            print(f\"Finished processing batch #{counter}\")\n        \n        counter += 1\n    \n    return concatenate_datasets(all_buckets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:41.855307Z","iopub.execute_input":"2025-04-15T17:07:41.855623Z","iopub.status.idle":"2025-04-15T17:07:41.861019Z","shell.execute_reply.started":"2025-04-15T17:07:41.855597Z","shell.execute_reply":"2025-04-15T17:07:41.860241Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"dataset_w_fewshot = obtain_few_shot_examples_in_batches(dataset['validation'], 50, 2)\ndataset_w_fewshot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:07:46.525390Z","iopub.execute_input":"2025-04-15T17:07:46.525724Z","iopub.status.idle":"2025-04-15T17:12:05.136035Z","shell.execute_reply.started":"2025-04-15T17:07:46.525697Z","shell.execute_reply":"2025-04-15T17:12:05.135308Z"}},"outputs":[{"name":"stdout","text":"Processing in batches of 50. Total number of batches: 238\nFinished processing batch #0\nFinished processing batch #50\nFinished processing batch #100\nFinished processing batch #150\nFinished processing batch #200\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'title', 'context', 'question', 'answers', 'few_shot'],\n    num_rows: 11873\n})"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"print(f\"Length of test dataset is: {len(dataset_w_fewshot)}\\nSample of single example: {dataset_w_fewshot[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:12:05.136954Z","iopub.execute_input":"2025-04-15T17:12:05.137232Z","iopub.status.idle":"2025-04-15T17:12:05.141907Z","shell.execute_reply.started":"2025-04-15T17:12:05.137204Z","shell.execute_reply":"2025-04-15T17:12:05.140943Z"}},"outputs":[{"name":"stdout","text":"Length of test dataset is: 11873\nSample of single example: {'id': '56ddde6b9a695914005b9628', 'title': 'Normans', 'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.', 'question': 'In what country is Normandy located?', 'answers': {'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}, 'few_shot': [{'answers': {'answer_start': [25], 'text': ['Austrian']}, 'context': 'Schwarzenegger is a dual Austrian/United States citizen. He holds Austrian citizenship by birth and has held U.S. citizenship since becoming naturalized in 1983. Being Austrian and thus European, he was able to win the 2007 European Voice campaigner of the year award for taking action against climate change with the California Global Warming Solutions Act of 2006 and plans to introduce an emissions trading scheme with other US states and possibly with the EU.', 'id': '56dec1673277331400b4d70e', 'question': 'In what country besides the U.S. is Schwarzenegger a citizen?', 'title': 'Arnold_Schwarzenegger'}, {'answers': {'answer_start': [41], 'text': ['South Kensington']}, 'context': \"Imperial's main campus is located in the South Kensington area of central London. It is situated in an area of South Kensington, known as Albertopolis, which has a high concentration of cultural and academic institutions, adjacent to the Natural History Museum, the Science Museum, the Victoria and Albert Museum, the Royal College of Music, the Royal College of Art, the Royal Geographical Society and the Royal Albert Hall. Nearby public attractions include the Kensington Palace, Hyde Park and the Kensington Gardens, the National Art Library, and the Brompton Oratory. The expansion of the South Kensington campus in the 1950s & 1960s absorbed the site of the former Imperial Institute, designed by Thomas Collcutt, of which only the 287 foot (87 m) high Queen's Tower remains among the more modern buildings.\", 'id': '570a55836d058f1900182d66', 'question': \"In which area in London is Imperial's main campus located?\", 'title': 'Imperial_College_London'}]}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"dataset_w_fewshot.to_parquet(\"squad_2_with_few_shot_gpt2.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:12:09.852954Z","iopub.execute_input":"2025-04-15T17:12:09.853358Z","iopub.status.idle":"2025-04-15T17:12:10.039267Z","shell.execute_reply.started":"2025-04-15T17:12:09.853330Z","shell.execute_reply":"2025-04-15T17:12:10.038319Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10c64fb024f145dd8b7f6fc910673191"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"33477879"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"dataset_w_fewshot.select(range(5000)).to_parquet(\"squad_2_with_few_shot_gpt2_5000.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:12:12.639698Z","iopub.execute_input":"2025-04-15T17:12:12.639985Z","iopub.status.idle":"2025-04-15T17:12:12.745978Z","shell.execute_reply.started":"2025-04-15T17:12:12.639964Z","shell.execute_reply":"2025-04-15T17:12:12.745338Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee4727ad54341e3a6afcbd4b8625bb8"}},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"14028484"},"metadata":{}}],"execution_count":31}]}