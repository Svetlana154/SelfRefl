{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11580999,"sourceType":"datasetVersion","datasetId":7167328}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nimport numpy as np\nimport json\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:30:18.722437Z","iopub.execute_input":"2025-04-17T03:30:18.723075Z","iopub.status.idle":"2025-04-17T03:30:20.520861Z","shell.execute_reply.started":"2025-04-17T03:30:18.723045Z","shell.execute_reply":"2025-04-17T03:30:20.520329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_filepath = \"/kaggle/working/qwen2-0.5B_eval.csv\"\n# dataset_filepaths = [\"/kaggle/input/flan-t5/flan-t5-base/iter_0_results.parquet\",\n#                     \"/kaggle/input/flan-t5/flan-t5-base/iter_1_results_refined.parquet\",\n#                     \"/kaggle/input/flan-t5/flan-t5-base/iter_2_results_refined.parquet\"]\ndataset_filepaths = [f\"/kaggle/input/flan-t5/qwen2-0.5B/iter_{iter_i}/results.parquet\" for iter_i in range(11)]\n\n# running test\nRUN_LIMITED_TEST = False\n\nevaluate_labels = {'truth_label': 'expected_answer',\n                   'predicted_label': 'predicted_answer'}\n\n# evaluate_labels = [{'truth_label': 'expected_answer',\n#                    'predicted_label': 'predicted_answer'},\n#                   {'truth_label': 'context',\n#                    'predicted_label': 'predicted_answer'},\n#                   {'truth_label': 'context',\n#                    'predicted_label': 'question_predicted_answer'}]\n# final_filepath_endings = ['_answer_vs_answer',\n#                          '_context_vs_answer',\n#                          '_context_vs_qpa']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:32:59.951373Z","iopub.execute_input":"2025-04-17T03:32:59.952110Z","iopub.status.idle":"2025-04-17T03:32:59.956318Z","shell.execute_reply.started":"2025-04-17T03:32:59.952082Z","shell.execute_reply":"2025-04-17T03:32:59.955574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepping for Evaluation","metadata":{}},{"cell_type":"code","source":"!pip install evaluate\n!pip install rouge_score\n!pip install bert_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:30:22.683366Z","iopub.execute_input":"2025-04-17T03:30:22.684058Z","iopub.status.idle":"2025-04-17T03:31:43.284790Z","shell.execute_reply.started":"2025-04-17T03:30:22.684031Z","shell.execute_reply":"2025-04-17T03:31:43.283481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from evaluate import load","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:31:43.286672Z","iopub.execute_input":"2025-04-17T03:31:43.287453Z","iopub.status.idle":"2025-04-17T03:32:07.580594Z","shell.execute_reply.started":"2025-04-17T03:31:43.287418Z","shell.execute_reply":"2025-04-17T03:32:07.579785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def obtain_basic_metrics(dataset, truth_label, predicted_label):\n    final = []\n    keys = ['exact_match',\n            'rouge1', 'rouge2', 'rougeL', 'rougeLsum', \n            'meteor',\n            'bert_score_model', 'bert_score_avg_precision', 'bert_score_avg_recall', 'bert_score_avg_f1',\n           ]\n    \n    exact_match_metric = load(\"exact_match\")\n    results = exact_match_metric.compute(predictions=dataset[predicted_label], references=dataset[truth_label], ignore_case=True, ignore_punctuation=True)\n    final.append(results['exact_match'])\n  \n    rouge = load(\"rouge\")\n    results = rouge.compute(predictions=dataset[predicted_label], references=dataset[truth_label])\n    final.append(results['rouge1'])\n    final.append(results['rouge2'])\n    final.append(results['rougeL'])\n    final.append(results['rougeLsum'])\n    \n    rouge = load(\"meteor\")\n    results = rouge.compute(predictions=dataset[predicted_label], references=dataset[truth_label])\n    final.append(results['meteor'])\n    \n    bertscore = load(\"bertscore\")\n    results = bertscore.compute(predictions=dataset[predicted_label], references=dataset[truth_label], lang=\"en\")\n\n    final.append(results['hashcode'])\n    final.append(np.mean(results['precision']))\n    final.append(np.mean(results['recall']))\n    final.append(np.mean(results['f1']))\n    # final['bert_score_model']\n    # final['bert_score_avg_precision']\n    # final['bert_score_avg_recall']\n    # final['bert_score_avg_f1']\n\n    return final, keys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:32:31.227428Z","iopub.execute_input":"2025-04-17T03:32:31.228241Z","iopub.status.idle":"2025-04-17T03:32:31.235515Z","shell.execute_reply.started":"2025-04-17T03:32:31.228215Z","shell.execute_reply":"2025-04-17T03:32:31.234525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mock\n# def obtain_basic_metrics(dataset_filepath, truth_label, predicted_label):\n#     return [dataset_filepath,2,3], ['a','b','c']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:32:35.025442Z","iopub.execute_input":"2025-04-17T03:32:35.025723Z","iopub.status.idle":"2025-04-17T03:32:35.029721Z","shell.execute_reply.started":"2025-04-17T03:32:35.025701Z","shell.execute_reply":"2025-04-17T03:32:35.028996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_dataset(dataset_filepath, truth_label, predicted_label):\n    dataset = load_dataset(\"parquet\", data_files=dataset_filepath)[\"train\"]\n    \n    if RUN_LIMITED_TEST:\n        dataset = dataset.select(range(150))\n        print(\"Running a test: computing 150 examples.\")\n    \n    metric_values, metric_names = obtain_basic_metrics(dataset, truth_label, predicted_label)\n    return metric_values, metric_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:32:37.005231Z","iopub.execute_input":"2025-04-17T03:32:37.005920Z","iopub.status.idle":"2025-04-17T03:32:37.010075Z","shell.execute_reply.started":"2025-04-17T03:32:37.005895Z","shell.execute_reply":"2025-04-17T03:32:37.009157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Run for All Datasets","metadata":{}},{"cell_type":"code","source":"all_metrics = []\n\nfor iter_i, filepath in enumerate(dataset_filepaths):\n    metric_values, metric_names = evaluate_dataset(filepath, \n                                                   evaluate_labels['truth_label'], \n                                                   evaluate_labels['predicted_label']\n                                                  )\n    all_metrics.append(metric_values)\n\n\nall_metrics_df = pd.DataFrame(all_metrics, columns = metric_names)\nall_metrics_df['iteration'] = range(len(dataset_filepaths))\nall_metrics_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:33:41.632886Z","iopub.execute_input":"2025-04-17T03:33:41.633493Z","iopub.status.idle":"2025-04-17T03:33:43.230489Z","shell.execute_reply.started":"2025-04-17T03:33:41.633468Z","shell.execute_reply":"2025-04-17T03:33:43.229870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_metrics_df.to_csv(final_filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:34:14.899753Z","iopub.execute_input":"2025-04-17T03:34:14.900373Z","iopub.status.idle":"2025-04-17T03:34:14.909408Z","shell.execute_reply.started":"2025-04-17T03:34:14.900350Z","shell.execute_reply":"2025-04-17T03:34:14.908770Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## obtain summac scores","metadata":{}},{"cell_type":"code","source":"print('COMPUTING SUMMAC SCORES')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install summac","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:34:23.312112Z","iopub.execute_input":"2025-04-17T03:34:23.312364Z","iopub.status.idle":"2025-04-17T03:34:42.736306Z","shell.execute_reply.started":"2025-04-17T03:34:23.312347Z","shell.execute_reply":"2025-04-17T03:34:42.735236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from summac.model_summac import SummaCConv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:34:44.451489Z","iopub.execute_input":"2025-04-17T03:34:44.452307Z","iopub.status.idle":"2025-04-17T03:34:44.933861Z","shell.execute_reply.started":"2025-04-17T03:34:44.452275Z","shell.execute_reply":"2025-04-17T03:34:44.933078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_conv = SummaCConv(models=[\"vitc\"], bins='percentile', granularity=\"sentence\", nli_labels=\"e\", device=\"cuda:0\", start_file=\"default\", agg=\"mean\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:34:48.492205Z","iopub.execute_input":"2025-04-17T03:34:48.492519Z","iopub.status.idle":"2025-04-17T03:34:49.010447Z","shell.execute_reply.started":"2025-04-17T03:34:48.492497Z","shell.execute_reply":"2025-04-17T03:34:49.009613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summac_scores = []\n\nfor iter_i, filepath in enumerate(dataset_filepaths):\n    print(f\"- Computing summac for {iter_i}\")\n    dataset = load_dataset(\"parquet\", data_files=filepath)[\"train\"]\n    \n    if RUN_LIMITED_TEST:\n        dataset = dataset.select(range(150))\n        print(\"Running a test: computing 150 examples.\")\n    \n    score_conv1 = model_conv.score(dataset[evaluate_labels['truth_label']], \n                                   dataset[evaluate_labels['predicted_label']])\n    summac_scores.append(np.mean(score_conv1['scores']))\n\nall_metrics_df['summac_conv_scores'] = summac_scores\nall_metrics_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:35:25.593791Z","iopub.execute_input":"2025-04-17T03:35:25.594560Z","iopub.status.idle":"2025-04-17T03:35:25.942551Z","shell.execute_reply.started":"2025-04-17T03:35:25.594535Z","shell.execute_reply":"2025-04-17T03:35:25.941712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_metrics_df.to_csv(final_filepath)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}